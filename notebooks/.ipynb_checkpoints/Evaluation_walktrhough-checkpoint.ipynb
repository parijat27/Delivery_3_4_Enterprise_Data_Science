{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3032a4fa",
   "metadata": {},
   "source": [
    "# Update all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720271b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of regions rows:16\n"
     ]
    }
   ],
   "source": [
    "# %load ../src/data/GER_data.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "def get_current_data_germany():\n",
    "    data = requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/Coronafälle_in_den_Bundesländern/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "    json_object = json.loads(data.content)\n",
    "\n",
    "    full_list = []\n",
    "    for pos,each_dict in enumerate (json_object['features'][:]):\n",
    "        full_list.append(each_dict['attributes'])\n",
    "        \n",
    "    pd_full_list = pd.DataFrame(full_list)\n",
    "    pd_full_list.to_csv('../data/raw/GER_state_data.csv', sep=';')\n",
    "    print('Number of regions rows:' +str(pd_full_list.shape[0]))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    get_current_data_germany()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c0d14e",
   "metadata": {},
   "source": [
    "# Process pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32734441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows stored:248805\n"
     ]
    }
   ],
   "source": [
    "# %load ../src/data/JH_data.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_JH_data():\n",
    "    data_path = '../data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw = pd.read_csv(data_path)\n",
    "    \n",
    "    pd_data_base = pd_raw.rename(columns={'Country/Region' : 'country', 'Province/State' : 'state'})\n",
    "    pd_data_base['state']=pd_data_base['state'].fillna('no')  #ensure a sring, important for indexing\n",
    "    \n",
    "    pd_data_base = pd_data_base.drop(['Lat', 'Long'],axis=1)\n",
    "    pd_relational_model = pd_data_base.set_index(['state', 'country'])                                             .T                                                                 .stack(level = [0,1])                                              .reset_index()                                                     .rename(columns={'level_0' : 'date' ,\n",
    "                                                            0 : 'confirmed'},\n",
    "                                                   )\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "    pd_relational_model.to_csv('../data/processed/COVID_relational_confirmed.csv',sep=';',index=False)\n",
    "    print('Number of rows stored:' +str(pd_relational_model.shape[0]))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    get_JH_data()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d138cbb9",
   "metadata": {},
   "source": [
    "# Slope calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cfe784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test slope is :[2.]\n",
      "         index       date    state     country  confirmed  confirmed_filtered  \\\n",
      "0            0 2020-01-22  Alberta      Canada        0.0                 0.0   \n",
      "158013  158013 2020-01-22       no      Kosovo        0.0                 0.0   \n",
      "158886  158886 2020-01-22       no      Kuwait        0.0                 0.0   \n",
      "159759  159759 2020-01-22       no  Kyrgyzstan        0.0                 0.0   \n",
      "160632  160632 2020-01-22       no        Laos        0.0                 0.0   \n",
      "\n",
      "        index_x  confirmed_DR  index_y  confirmed_filtered_DR  \n",
      "0             0           NaN        0                    NaN  \n",
      "158013        1           NaN   158013                    NaN  \n",
      "158886        2           NaN   158886                    NaN  \n",
      "159759        3           NaN   159759                    NaN  \n",
      "160632        4           NaN   160632                    NaN  \n"
     ]
    }
   ],
   "source": [
    "# %load ../src/data/build_features.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate'''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "\n",
    "def savgol_filter(df_input, column='confirmed', window = 5):\n",
    "    degree = 1\n",
    "    df_result = df_input\n",
    "    \n",
    "    filter_in=df_input[column].fillna(0)\n",
    "\n",
    "    result = signal.savgol_filter(np.array(filter_in),\n",
    "                           5, # window size used for filtering\n",
    "                           1) # order of fitted polynomial\n",
    "    \n",
    "    df_result[column+'_filtered'] = result\n",
    "\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg (df_input, col='confirmed'):\n",
    "    days_back = 3\n",
    "    result = df_input[col].rolling(\n",
    "                                window=days_back,\n",
    "                                min_periods=days_back).apply(get_doubling_time_via_regression, raw=False)\n",
    "    return result\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "    \n",
    "    pd_filtered_result=df_input[['state','country',filter_on]].groupby(['state','country']).apply(savgol_filter).reset_index()\n",
    "    #df_output=pd.merge(df_input,pd_filtered_result[['index',filter_on+'_filtered']],on=['index'],how='left')\n",
    "    df_output=pd.merge(df_input,pd_filtered_result[[str(filter_on+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "\n",
    "    return df_output\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "\n",
    "    pd_DR_result= df_input.groupby(['state','country']).apply(rolling_reg,filter_on).reset_index()\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_2':'index'})\n",
    "\n",
    "    #we do the merge on the index of our big table and on the index column after groupby\n",
    "    #df_output=pd.merge(df_input,pd_DR_result[['index',filter_on+'_DR']],on=['index'],how='left')\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',str(filter_on+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "\n",
    "    return df_output\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_data = np.array([2,4,6])\n",
    "    result = get_doubling_time_via_regression(test_data)\n",
    "    print ('test slope is :' + str(result))\n",
    "    \n",
    "    pd_JH_data=pd.read_csv('../data/processed/COVID_relational_confirmed.csv',sep=';',parse_dates=[0])\n",
    "    pd_JH_data=pd_JH_data.sort_values('date',ascending=True).reset_index(drop=True).copy()\n",
    "    \n",
    "    pd_result_larg=calc_filtered_data(pd_JH_data)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg,'confirmed_filtered')\n",
    "    print(pd_result_larg.head())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e1631",
   "metadata": {},
   "source": [
    "# Visual board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb363f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/data/visualize.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import dash\n",
    "dash.__version__\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "print(os.getcwd())\n",
    "df_input_large=pd.read_csv('../data/processed/COVID_final_set.csv',sep=';')\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([\n",
    "    \n",
    "    dcc.Markdown('''\n",
    "    #  Applied Data Science on COVID-19 data\n",
    "\n",
    "    Goal of the project is to teach data science by applying a cross industry standard process,\n",
    "    it covers the full walkthrough of: automated data gathering, data transformations,\n",
    "    filtering and machine learning to approximating the doubling time, and\n",
    "    (static) deployment of responsive dashboard.\n",
    "\n",
    "    '''),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    ## Multi-Select Country for visualization\n",
    "    '''),\n",
    "    \n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_down',\n",
    "        options=[ {'label': each,'value':each} for each in df_input_large['country'].unique()],\n",
    "        value=['US', 'Germany','Italy'], # which are pre-selected\n",
    "        multi=True\n",
    "    ),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "        ## Select Timeline of confirmed COVID-19 cases or the approximated doubling time\n",
    "        '''),\n",
    "\n",
    "\n",
    "    dcc.Dropdown(\n",
    "    id='doubling_time',\n",
    "    options=[\n",
    "        {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "        {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "        {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "        {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'},\n",
    "    ],\n",
    "    value='confirmed',\n",
    "    multi=False\n",
    "    ),\n",
    "\n",
    "    dcc.Graph(figure=fig, id='main_window_slope')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_drop_down', 'value'),\n",
    "    Input('doubling_time', 'value')])\n",
    "def update_figure(country_list,show_doubling):\n",
    "\n",
    "\n",
    "    if 'doubling_rate' in show_doubling:\n",
    "        my_yaxis={'type':\"log\",\n",
    "               'title':'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "              }\n",
    "    else:\n",
    "        my_yaxis={'type':\"log\",\n",
    "                  'title':'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "              }\n",
    "\n",
    "\n",
    "    traces = []\n",
    "    for each in country_list:\n",
    "\n",
    "        df_plot=df_input_large[df_input_large['country']==each]\n",
    "\n",
    "        if show_doubling=='doubling_rate_filtered':\n",
    "            df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.mean).reset_index()\n",
    "        else:\n",
    "            df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "       #print(show_doubling)\n",
    "\n",
    "\n",
    "        traces.append(dict(x=df_plot.date,\n",
    "                                y=df_plot[show_doubling],\n",
    "                                mode='markers+lines',\n",
    "                                opacity=0.9,\n",
    "                                name=each\n",
    "                        )\n",
    "                )\n",
    "\n",
    "    return {\n",
    "            'data': traces,\n",
    "            'layout': dict (\n",
    "                width=1280,\n",
    "                height=720,\n",
    "\n",
    "                xaxis={'title':'Timeline',\n",
    "                        'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                      },\n",
    "\n",
    "                yaxis=my_yaxis\n",
    "        )\n",
    "    }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run_server(debug=True, use_reloader=False)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb365185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
